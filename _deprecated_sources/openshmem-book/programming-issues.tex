%
% Copyright (c) 2011, 2012
%   University of Houston System and Oak Ridge National Laboratory.
% 
% All rights reserved.
% 
% Redistribution and use in source and binary forms, with or without
% modification, are permitted provided that the following conditions
% are met:
% 
% o Redistributions of source code must retain the above copyright notice,
%   this list of conditions and the following disclaimer.
% 
% o Redistributions in binary form must reproduce the above copyright
%   notice, this list of conditions and the following disclaimer in the
%   documentation and/or other materials provided with the distribution.
% 
% o Neither the name of the University of Houston System, Oak Ridge
%   National Laboratory nor the names of its contributors may be used to
%   endorse or promote products derived from this software without specific
%   prior written permission.
% 
% THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
% ``AS IS'' AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
% LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
% A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
% HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
% SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED
% TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
% PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF
% LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING
% NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
% SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
%


\chapter{\openshmem Programming Pitfalls}

Or better yet, how to avoid them and what to do, with handy-dandy
examples of code improvements.

\section{When is a Put actually put?}

\subsection{Assuming puts are sent when they're not}

% When things are on-the-wire but haven't been received yet.  Contrast
% with ``get''.  How do I ensure this?  Example needed.

The \openshmem model is that of \emph{deferred} synchronization.  We
will see below how this helps parallel programming.  What this means
is that a ``put'' call returns and computation continues locally even
though the data involved in the ``put'' may not have been delivered
yet, which is described as \emph{on the wire}.

The following code snippet shows this situation:

\begin{minipage}{\linewidth}
\vspace{0.1in}
\numberedlisting{label=put-ordering,language=OSH+C}{programs/put-ordering.c}
\vspace{0.1in}
\end{minipage}

When the 2 ``put'' calls have returned and local computation
continues, all we know is that the

\begin{minipage}{\linewidth}
\begin{itemize}
\item source data from arrays \texttt{s1} and \texttt{s2} are en route
\item the contents of \texttt{s1} and \texttt{s2} may be changed
  safely by the sender without affecting what is sent.
\end{itemize}
\end{minipage}

It \emph{may} have been fully delivered to the destination PE, or it
may not.  It is not until a synchronization point (here a global
barrier) that we can guarantee the data from the source arrays has
been written to the target arrays on the destination PEs.

\subsection{Assuming order-of-delivery}

% Some programs that try to rely on o-o-d and how this can trip you up.

\openshmem ``put'' calls do not complete when they return: the store
at the target is only guaranteed after a synchronization point such as
``fence''.  Further, \openshmem knows nothing about the underlying
transport that actually moves data from a particular PE to a target.
The transport could be shared-memory, or a network like Infiniband or
Ethernet.  Some transports manipulate the data being sent on them.
Examples of such manipulation are

\begin{description}
\item[re-ordering:] the transport may choose to send data in ``put''
  calls in a different order to the order that appears to someone
  reading the source code.
\item[asymmetric transports:] an underlying network may send data on
  different paths to a target depending on circumstances, e.g.\ to
  avoid congestion or to aid fan-out across machines in a cluster.
\item[coalescing:] multiple ``puts'' to a given target may be held
  back and merged into a single transfer to reduce the amount of
  traffic and avoid the latency incurred by separate ``puts''.
\end{description}

Referring to iisting~\ref{put-ordering}, depending on the environment
where this program runs, an underlying transport may send the 2
``puts'' in any order: the smaller 8 int put may occur first if the
current route to PE 2 is ``quieter'', even though there is
\emph{textually} another ``put'' before it.

\section{Communication vs.\ Computation}

\subsection{Failing to spot overlap opportunities}

How to reorder applications to make the communication as
early-as-possible and synchronization as late-as-possible, and
therefore maximize the amount of work that can be done in the
meantime.

\section{Synchronization}

\subsection{Not synchronizing in the right places}

E.g.\ where each PE initializes some data independently then tries
to use that data in a collective.  How to think about ``readiness''
in a symmetric way.

Memory that is to be accessed remotely (e.g.\ it will be the target of
a ``put'' from another PE) must be ready on all PEs before use.  By
\emph{ready} we mean it must be both

\begin{itemize}
\item allocated, and;
\item initialized (if needed)
\end{itemize}

before any communication call uses the memory.  A common mistake is to
allocate memory, initialize it to some values, and then immediately
proceed to a sequence of ``puts'' or a collective routine: although
the allocation and initialize have completed locally, we do not know
if this sequence has finished on other PEs yet.

This leads to attempts to use unallocated memory (often this will
cause a segmentation violation); or allocated memory will not have been
initialized and incorrect values will be transmitted or used, e.g.\ in a
collective call like a reduction.

A synchronization point is required before such symmetrically
allocated memory is used.  Often a global \texttt{shmem\_barrier\_all}
will be used as calls like \texttt{shmalloc} are globally collective.

\begin{minipage}{\linewidth}
\vspace{0.1in}
\numberedlisting{label=synch-not-needed,language=OSH+C}{programs/synch-not-needed.c}
\vspace{0.1in}
\end{minipage}

The barrier on line 7 is required to make sure that \texttt{pSync} has
been fully initialized across all participating PEs before any PE
enters the reduction.  Without synchronization it is possible for PEs
to ``fall through'' if \texttt{pSync} accidentally has a value that
indicates the PE can start to walk through the barrier.

\subsection{Over-synchronizing in the wrong places}

% Sometimes you're not sure whether you need a synchronization at some
% point and may put one in where it is not needed, or you're not
% exploiting the overlap paradigm and are instead trying to
% coerce \openshmem into a matched send-receive mode.

It is also possible to introduce unnecessary synchronizations.  These
do not affect the \emph{correctness} of the program, but can introduce
a slowdown.  Collective reduction routines, for example, ensure that
the reduced data has been stored on all participating PEs upon return.
Therefore there is no need to introduce a further synchronization
before examining the results.

The global barrier on line 11 of listing~\ref{synch-not-needed} is not
needed, as the \\ \texttt{shmem\_long\_sum\_to\_all} has already made
sure that remote stores of \texttt{target} have been completed and
\texttt{target} is safe to use on all PEs that participated in the
reduction.~\footnote{the content of \texttt{target} is unchanged on PEs
  outside of the active set.}

\subsection{Summary: too little or too much synchronization}

Too little synchronization will lead to incorrect results or other
aberrant behavior such as hangs or program crashes.

Too much synchronization will not introduce any change of behavior,
but may introduce slowdown due to the overhead of extra calls.
